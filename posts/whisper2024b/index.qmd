---
title: "AI Transcription from R using Whisper: Part 2"
description: "Speedup on Windows using WSL2 and CUDA"
author: "Jeffrey Girard"
date: "2024-08-16"
image: whisper.webp
draft: false
categories:
  - teaching
  - audio
  - AI
---

## Introduction

In a [previous blog post](../whisper2024/index.qmd), I discussed using the audio.whisper R package to do local, AI-based audio transcription. It worked well but was prohibitively slow (e.g., ~1 minute to process each second of audio). In this blog post, I will discuss how to achieve considerable speed improvements on Windows through a combination of hardware and software. Parts will be more technical but hang in there and I'll do my best to make it achievable. 

Before we dive into things, I'll provide a brief overview of all the steps. 

1. Check that our computer's hardware supports CUDA
1. Install/update the NVIDIA graphics driver on Windows
1. Install and update the Windows Subsystem for Linux (WSL2) on Windows
1. Install and setup the Ubuntu operating system via WSL2
1. Install the CUDA Toolkit for WSL on Ubuntu
1. Install R and dependency packages on Ubuntu
1. Install audio.whisper R package with CUDA support on Ubuntu
1. Test it out

## Check for CUDA Support

This post assumes that you are using the Windows operating system and that your computer's graphics card supports [CUDA](https://developer.nvidia.com/cuda-faq). To check that this is the case, first look up your graphics card's model number. An easy way to do this is on Windows 10/11 is to click on the desktop search bar (bottom-left of the screen next to the windows icon) and type in "Device Manager." Then click the arrow next to "Display adapters" and find your graphics card's model name. On my computer, it says "NVIDIA GeForce RTX 2060." Then go to  [this link](https://developer.nvidia.com/cuda-gpus) and click the "CUDA-Enabled NVIDIA Quadro and NVIDIA RTX" and "CUDA-Enabled GeForce and TITAN Products" blocks to open their accordions. Then search for your graphics card's model number (the left tables are for desktop cards and the right tables are for notebook cards). I found "GeForce RTX 2060" on the list under GeForce and TITAN Products with a compute capability of 7.5. Thus, my card is supported!

## Install the Newest NVIDIA Graphics Driver

Download and install the newest graphics driver for your card from [NVIDIA](https://www.nvidia.com/Download/index.aspx#). You should choose the Game Ready version. Note that you should *not* install the CUDA toolkit on Windows as doing so may confuse things and lead to issues later on (as we will be installing the CUDA toolkit for WSL in a later step).

## Install and Update the Windows Subsystem for Linux

Open the Microsoft Store app (e.g., using the desktop search bar) and search for the "Windows Subsystem for Linux." If it doesn't come up in the search results, you may already have it installed - you can check this by clicking the "Library" button on the left sidebar in the app and searching for it there. If it does come up, click on the Install button. It may be a good idea to restart your computer after it finishes installing. Then open the Command Prompt app (e.g., using the desktop search bar) and enter the following command: `wsl --update`. This will ensure that you have the most recent version of WSL2 installed.

## Install and Setup Ubuntu

In the Command Prompt app, enter the following command: `wsl --install Ubuntu`. This will install the Ubuntu Linux operating system over the course of several minutes. After installation, it will prompt you to create a UNIX username and password. Use whatever you want but don't lose this information as you will need it again later. 

## Install the CUDA Toolkit for WSL

In the Ubuntu console (which is opened automatically after Ubuntu is installed), enter or paste the following commands to install the CUDA Toolkit for WSL-Ubuntu. It will ask you to enter your password (created in the previous step) and may take several minutes to complete.

```default
wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin
sudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/12.6.0/local_installers/cuda-repo-wsl-ubuntu-12-6-local_12.6.0-1_amd64.deb
sudo dpkg -i cuda-repo-wsl-ubuntu-12-6-local_12.6.0-1_amd64.deb
sudo cp /var/cuda-repo-wsl-ubuntu-12-6-local/cuda-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt-get -y install cuda-toolkit-12-6
```

:::{.callout-note}
The command above may become outdated in the future (e.g., installing an older version of the toolkit). To find the most recent command, visit [this page from NVIDIA](https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=WSL-Ubuntu&target_version=2.0&target_type=deb_local).
:::

:::{.callout-important}
Do not install any NVIDIA graphics drivers on Ubuntu directly. Ubuntu will inherit the Windows drivers you installed in a previous step via WSL.
:::

:::{.callout-important}
If you get timeout errors when trying to install things on WSL, check to make sure that you are not connected to a VPN on Windows as this can mess things up.
:::

## Install R on Ubuntu

In the Ubuntu console, enter or paste the following commands to install R and other packages commonly used by R. You may have to hit ENTER and enter `Y` several times when prompted to do so.

```default
wget -qO- https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc | sudo tee -a /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc
sudo add-apt-repository "deb https://cloud.r-project.org/bin/linux/ubuntu $(lsb_release -cs)-cran40/"
sudo apt install -y --no-install-recommends r-base
sudo apt-get install -y libcurl4-openssl-dev libssl-dev libxml2-dev libudunits2-dev libgdal-dev cargo libfontconfig1-dev libcairo2-dev
sudo add-apt-repository ppa:c2d4u.team/c2d4u4.0+
sudo apt upgrade
sudo apt install -y --no-install-recommends r-cran-devtools r-cran-av
```

## Install audio.whisper with CUDA Support on Ubuntu

In the Ubuntu console, enter `sudo R` to open the R console. You will then need to set several environmental variables before installing the audio.whisper package from GitHub. Do so by entering or pasting the following commands into the R console:

```r
Sys.setenv(PATH = sprintf("%s:/usr/local/cuda-12.6/bin", Sys.getenv("PATH")))
Sys.setenv(CUDA_PATH = "/usr/local/cuda-12.6")
Sys.setenv(WHISPER_CUBLAS = "1")
remotes::install_github("bnosac/audio.whisper")
```

:::{.callout-note}
If you followed the instructions in the previous Note callout and installed a version of the CUDA Toolkit newer than 12.6, you will need to put the newer version number into the commands above (e.g., `/usr/local/cuda-12.7`).
:::

## Test and Time the Model

### Base Model and Short Audio Clip

In the R console, load the audio.whisper package and try it out on the JFK clip that took so long to process in the previous blog post. Note that there will be one important change to the commands from before. This time, when we load the model using the `whisper()` function, we will add the `use_gpu = TRUE` argument.

```r
# Load the package from library
library(audio.whisper)

# Download or load from file the desired model (with GPU support)
model <- whisper("base", use_gpu = TRUE)

# Construct file path to example audio file in package data
jfk <- system.file(package = "audio.whisper", "samples", "jfk.wav")

# Run English transcription using the downloaded whisper model
out <- predict(model, newdata = jfk, language = "en")

# Print transcript
out$data
```

```{r}
#| echo: false

out <- readRDS("C:/Users/jeffg/jfk.rds")
out$data |> kableExtra::kbl() |> kableExtra::kable_styling()
```

The results look good/the same as before, but check out the timing!!!

```{r}
#| collapse: true

out$timing
```

### Large Model and Long Audio Clip

With such a boost in speed, we can afford to try a larger model (e.g., `"large-v3"`) on a longer audio clip (e.g., a 1.35 min poetry reading by Gerard Malanga that is rather noisy and therefore a good test of the model's accuracy in real-world settings). This is also a chance to show how to process a file downloaded from the internet, in case that is of interest to any readers. We'll use the following commands in the R console in Ubuntu:

```r
# Load package from library (it was installed earlier via apt)
library(av)

# Download audio file from ubu.com
download.file(
  url = "https://ubu.com/media/sound/malanga_gerard/archives/Malanga-Gerard_Archives_01-Gerard-Malanga_To-The-Young-Model-Name-Unknown.mp3", 
  destfile = "malanga.mp3", 
  mode = "wb"
)

# Convert audio from mp3 to 16 kHz wav
av_audio_convert(
  "malanga.mp3", 
  output = "malanga.wav", 
  format = "wav", 
  sample_rate = 16000
)

# Download or load from file the large model with GPU support
model <- whisper("large-v3", use_gpu = TRUE)

# Run English transcription using the downloaded whisper model
out <- predict(model, newdata = "output.wav", language = "en")

# Print the transcript
out$data
```

```{r}
#| echo: false

out <- readRDS("C:/Users/jeffg/malanga.rds")
out$data |> kableExtra::kbl() |> kableExtra::kable_styling()
```

The results look really good despite the background noise. And check out the timing.

```{r}
#| collapse: true

out$timing
```

## Wrap-up

If you want to save the transcript, you can enter the following command in the R console: `saveRDS(out, "malanga.rds")` and it will create a serialized R data file containing all the transcript data (e.g., text and time stamps). By default, this file will be saved in the same folder on your Windows file system that you ran the Command Prompt app from (e.g., "C:/Users/jeffg"). However, you can save anywhere using WSL's `/mnt/` system. For example, if you wanted to save it to "C:/Users/jeffg/Desktop", then you would use `"/mnt/c/jeffg/Desktop/malanga.rds"` as the second argument to `saveRDS()`. Or if you wanted to save it to a mapped network drive like "Z:/affcomlab/transcription", then you would use `"/mnt/z/affcomlab/transcription/malanga.rds"`.

That wraps up this blog post. In the next part, I will discuss more practical aspects of using this technology. For example, I'll talk about how to generate a list of audio/videos files on your hard drive (or elsewhere) and then iterate over them to create transcripts from many files all at once.

*Part 3 coming soon...*
