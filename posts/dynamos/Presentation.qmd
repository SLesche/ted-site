---
format: 
  revealjs:
    css: styles.css
    slide-number: "c/t"
    overview: true
    progress: true
    mouse-wheel: true
    incremental: true
    lang: "en"
    pagetitle: "DynAMoS Database Slides"
    author-meta: "Jeffrey Girard"
    date-meta: "2023-09-13"
---

::: {.my-title}
# DynAMoS Database
[Dynamic Affective Movie Clip<br />Database for Subjectivity Analysis]{.my-subtitle}

::: {.my-details}
[ACII 2023 | Girard, Tie, & Liebenthal]{}<br />
{{< fa link size=xs >}} [<https://dynamos.mgb.org>]{.p90}
:::

![](movie.svg){.absolute bottom=20 right=0 width=360}
:::

## Emotion Elicitation using Film

- **Researchers often try to [elicit emotions]{.blue} in participants**
    + *To study the effects of emotion on other phenomena*
    + *To identify correlates of and group differences in emotion*
    + *To detect and quantify affect and affective dysregulation*

- **Affective [movie clips]{.blue} are common for elicitation stimuli**
    + Expertly crafted by actors, directors, etc.
    + Multimodal, dynamic, and extended in nature

## Types of Emotion Ratings {.p90}

- **Who is providing the measure of emotion?**
    + [Self]{.b .blue}-reports of participants' own emotional experience
    + [Observer]{.b .blue}-perceptions of participants' emotional experience

- **What model of emotion is used to report emotion?**
    + [Discrete]{.b .blue} choices of emotion categories (e.g, happy, angry)
    + [Continuous]{.b .blue} scores on emotion dimensions (e.g., valence)
    
- **How often are the emotions reported?**
    + [Holistic]{.b .blue} ratings collected once after the movie clip
    + [Dynamic]{.b .blue} ratings collected repeatedly during movie clip


## Archetypical Study Designs {.p90}

- **Psychology**
    + Large samples (>50 participants) of holistic self-reports
    + Focus on explaining differences between participants

- **Affective Computing**
    + Small samples (<10 participants) of dynamic observer-ratings
    + Focus on predicting the average perception from video features
    
- **A Proposed Hybrid: [Subjectivity Analysis]{.blue}**
    + Large samples (>50 participants) of dynamic self-reports
    + Focus on explaining differences between participants

## Subjectivity Analysis

Example Research Questions

- Why do participants experience the same stimuli differently?

- How structured/predictable are these individual differences?

- Are some stimuli (or moments) more subjective than others?

- How well can we predict/explain a stimulus's subjectivity?

- Can subjectivity analysis help us improve **personalization**?

- Can subjectivity analysis help us explain/model **ambiguity**?

## Available Databases

- Affective Movie Clip Databases with Dynamic Self-Reports
    + [DECAF](https://doi.org/10.1109/TAFFC.2015.2392932): 7 participants watch 36 clips (1--2 min each)
    + [COGNIMUSE](https://cognimuse.cs.ntua.gr/database): 7 participants watch 7 clips (30 min each)

- Limitations for Subjectivity Analysis
    + We need more participants for studying subjectivity
    + We need *intermediate* clip durations (2--10 min)
    
- **We designed a new database to meet these needs...**

## DynAMoS Database

::: {.nonincremental}
- **Movie Clip Selection**
    + 22 movie clips (1999--2018, 2.2--7.1 min, diverse content)

- **Participant Recruitment**
    + Healthy community members from *Rally with MGB*
    + 83 participants (56 female, 26 male)
    + 18--59 years old (M=28.8, SD=9.9)
    + 43 White, 22 Asian, 12 Black, 5 Other; 11 Hispanic/Latino

:::

## Procedure

1. Complete demographic **questionnaires**

2. Read brief **text description** of clip's (non-affective) context

3. Watch clip while providing **dynamic affect ratings**
    + [CARMA](https://carma.jmgirard.com) used to self-report emotional valence at 1 Hz

4. After clip ends, provide **holistic affect ratings**
    + [S-PANAS](10.1016/S0191-8869(98)00251-7) used to self-report positive and negative affect

5. **Repeat** Steps 2--4 for all clips (across two sessions)

## Quantifying Subjectivity

![](river.png)

::: {.footer}
Estimates from a Bayesian G study ([github.com/jmgirard/varde](https://github.com/jmgirard/varde))
:::

## Validation Take-aways {.p90}

- **Dynamic Ratings**
    - There was a lot of subjectivity (i.e., rater variance)
    - But the average of all raters' scores was very reliable
    - Lots of clip-by-rater and second-by-rater effects
- **Holistic Ratings**
    - Relatively less subjective than dynamic ratings
    - Inter-rater reliability was high across all clips
    - Inter-item reliability was high for *most* clips

::: {.footer}
See the database paper or website for details
:::

## Visualizing many time series

```{r}
#| echo: false
#| message: false
#| cache: true

library(tidyverse)
df <- read_rds("valence_tidy.rds")

s_to_ts <- function(s, force_hours = FALSE, round_seconds = TRUE) {
  
  p <- lubridate::seconds_to_period(s)
  h <- lubridate::hour(p)
  m <- lubridate::minute(p)
  s <- lubridate::second(p)
  
  if (any(h[is.finite(h)] > 0) || force_hours) {
    if (round_seconds) {
      out <- sprintf("%02d:%02d:%02d", h, m, round(s))
    } else {
      out <- sprintf("%02d:%02d:%02.3f", h, m, s)
    }
  } else {
    if (round_seconds) {
      out <- sprintf("%02d:%02d", m, round(s))
    } else {
      out <- sprintf("%02d:%02.3f", m, s)
    }
  }
  
  out[!is.finite(p)] <- NA_character_
  
  out
}

df2 <- df |> 
  filter(Abbrev == "GreenMile")

df2 |> 
  ggplot(aes(x = Second, y = Rating, group = Rater)) +
  geom_line(alpha = 1/5, color = "blue", linewidth = 1.5) +
  ggplot2::geom_hline(
      yintercept = 0, 
      color = "grey", 
      linewidth = 3/4
  ) +
  #(alpha = 1/10, color = "blue") +
  labs(
    x = 'Timestamp within Clip ("The Green Mile")',
    y = "Dynamic Valence Rating"
  ) +
  scale_x_continuous(
      breaks = seq(0, 10*2*30, 30), 
      expand = c(0, 0),
      labels = s_to_ts
  ) +
  theme_bw(base_size = 20) +
  theme(panel.grid.minor = element_blank())
```

::: {.footer}
Each blue line is one participant's time series
:::

## *Chromodoris quadricolor*

![](chromodoris.png)

## Introducing the Chromodoris plot

```{r}
#| message: false
#| echo: false
#| warning: false
#| cache: true

  require("Hmisc")
  df2 |> 
    ggplot2::ggplot(
      ggplot2::aes(x = Second, y = Rating)
    ) +
    ggplot2::stat_summary(
      geom = "ribbon",
      fun.data = ggplot2::median_hilow,
      fun.args = list(conf.int = .9),
      fill = "#440154"
    ) +
    ggplot2::stat_summary(
      geom = "ribbon",
      fun.data = ggplot2::median_hilow,
      fun.args = list(conf.int = .7),
      fill = "#21908c"
    ) +
    ggplot2::stat_summary(
      geom = "ribbon",
      fun.data = ggplot2::median_hilow,
      fun.args = list(conf.int = .5),
      fill = "#fde725"
    ) +
    ggplot2::geom_hline(
      yintercept = 0, 
      color = "grey", 
      linewidth = 3/4
    ) +
    ggplot2::stat_summary(
      geom = "line", 
      fun = mean, 
      na.rm = TRUE, 
      linewidth = 1.5
    ) +
    ggplot2::scale_x_continuous(
      breaks = seq(0, 10*2*30, 30), 
      expand = c(0, 0),
      labels = s_to_ts
    ) +
    ggplot2::scale_y_continuous(
      expand = c(0, 0)
    ) +
    ggplot2::coord_cartesian(
      ylim = c(-4, 4)
    ) +
    ggplot2::labs(
      y = "Dynamic Valence Rating", 
      x = 'Timestamp within Clip ("The Green Mile")'
    ) +
    theme_bw(base_size = 20) +
    theme(panel.grid.minor = element_blank())

```

::: {.footer}
Black = Mean, Yellow = 50%, Green = 70%, Purple = 90%
:::


## Website Generation

::: {.nonincremental}
- Rich documentation for the database
    + <https://dynamos.mgb.org>
    + Summary tables, figures, explanatory text
    + Screenshots of clips, subtitles, and features

- Built using [Quarto](https://quarto.org) and hosted using [GitLab Pages](https://docs.gitlab.com/ee/user/project/pages/)
    + Can be easily updated as the database grows
    + Can showcase the R code used to analyze data

:::

## Database Uses

- **Emotion elicitation** video set with normative data 

- Affective **content analysis** with average ratings

- Subjectivity analysis to predict **rating distributions**

- Subjectivity analysis to explain **degree of subjectivity**

- **Personalized modeling** of affective reactions

## Future Directions

1. Add more movie **clips** and **participants**

1. Add more dynamic and holistic rating **dimensions**

1. Add data from **sensors** (e.g., physiological and eye tracking)

1. Collect information about participants' **personality**

1. Collect similar data in other **languages/countries**

1. Collect similar data in **clinical/medical** populations

## Acknowledgements

::: {.nonincremental}

- **Co-authors**
    + Yanmei Tie (Brigham & Women's Hospital, HMS)
    + Einat Liebenthal (McLean Hospital, HMS)

- **Funding:**
    + Alexandra Golby (Brigham & Women's Hospital, HMS)

- **Assistance:**
    + Colin Gavin, Laura Rigolo, Abby Recko, Ben Phan
    
:::
    
## Questions? {.tc}

![](movie.svg)

<https://dynamos.mgb.org>
