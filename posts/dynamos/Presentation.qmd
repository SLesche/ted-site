---
format: 
  revealjs:
    css: styles.css
    slide-number: "c/t"
    overview: true
    progress: true
    mouse-wheel: false
    controls: true
    incremental: true
    lang: "en"
    pagetitle: "DynAMoS Database Slides"
    author-meta: "Jeffrey Girard"
    date-meta: "2023-09-13"
---

::: {.my-title}
# DynAMoS Database
[Dynamic Affective Movie Clip<br />Database for Subjectivity Analysis]{.my-subtitle}

::: {.my-details}
[ACII 2023 | Girard, Tie, & Liebenthal]{}<br />
{{< fa link size=xs >}} [<https://dynamos.mgb.org>]{.p90}
:::

![](movie.svg){.absolute bottom=20 right=0 width=360}
:::

## Types of Emotion Ratings {.p90}

- **Who is providing the measure of emotion?**
    + [Self]{.b .blue}-reports of participants' own emotion
    + [Observer]{.b .blue}-perceptions of others' emotion

- **How is emotion being represented?**
    + [Discrete]{.b .blue} choices of emotion categories (e.g, happy, angry)
    + [Continuous]{.b .blue} scores on emotion dimensions (e.g., valence)
    
- **How often are the emotions reported?**
    + [Holistic]{.b .blue} ratings collected once after each stimulus
    + [Dynamic]{.b .blue} ratings collected repeatedly during each stimulus

## Ambiguity and Subjectivity

- Emotion ratings will inevitably vary between raters...

- We usually treat such variability as a ***nuisance*** to "fix"
    
- But we can gain a lot by embracing these differences: studying their sources and building them into our models
    
- [Ambiguity]{.b .blue}: variability across different *observers' perceptions* of the emotion in a given stimulus (see [Sethu et al., 2019](https://arxiv.org/abs/1909.00360))

- [Subjectivity]{.b .red}: variability across different *subjects' self-reports* of the emotion they experienced from a given stimulus

## DynAMoS Database

::: {.nonincremental}
- **Participants**
    + Healthy community members from *Rally with MGB*
    + 83 participants (67% female, 18--59 years old)
    + 43 White, 22 Asian, 12 Black, 5 Other; 11 Hispanic/Latino

- **Procedure**
    + Watch 22 affective movie clips (2.2--7.1 minutes each)
    + Dynamic self-reported emotional valence ([CARMA](https://carma.jmgirard.com))
    + Holistic self-reported positive/negative affect ([S-PANAS](10.1016/S0191-8869(98)00251-7))
:::

## Emotional Ratings

::: {.columns}
::: {.column}
### Dynamic
--4 (*negative*) to +4 (*positive*)<br>
Rated at 30 Hz, binned to 1 Hz
![](fig_carma.png)
:::
::: {.column}
### Holistic 
Each rated 0 (*very slightly or not at all*) to 4 (*extremely*):

[Positive Affect]{.blue}<br>alert, determined, enthusiastic, excited, inspired

[Negative Affect]{.blue}<br>afraid, distressed, nervous, upset, scared

:::
:::

::: {.footer}
<https://carma.jmgirard.com>
:::

## Quantifying Subjectivity

![](river.png)

::: {.footer}
Estimates from a Bayesian G study ([github.com/jmgirard/varde](https://github.com/jmgirard/varde))
:::

## Visualizing many time series is hard...

```{r}
#| echo: false
#| message: false
#| cache: true

library(tidyverse)
df <- read_rds("valence_tidy.rds")

s_to_ts <- function(s, force_hours = FALSE, round_seconds = TRUE) {
  
  p <- lubridate::seconds_to_period(s)
  h <- lubridate::hour(p)
  m <- lubridate::minute(p)
  s <- lubridate::second(p)
  
  if (any(h[is.finite(h)] > 0) || force_hours) {
    if (round_seconds) {
      out <- sprintf("%02d:%02d:%02d", h, m, round(s))
    } else {
      out <- sprintf("%02d:%02d:%02.3f", h, m, s)
    }
  } else {
    if (round_seconds) {
      out <- sprintf("%02d:%02d", m, round(s))
    } else {
      out <- sprintf("%02d:%02.3f", m, s)
    }
  }
  
  out[!is.finite(p)] <- NA_character_
  
  out
}

df2 <- df |> 
  filter(Abbrev == "GreenMile")

df2 |> 
  ggplot(aes(x = Second, y = Rating, group = Rater)) +
  geom_line(alpha = 1/5, color = "blue", linewidth = 1.5) +
  ggplot2::geom_hline(
      yintercept = 0, 
      color = "grey", 
      linewidth = 3/4
  ) +
  #(alpha = 1/10, color = "blue") +
  labs(
    x = 'Timestamp within Clip ("The Green Mile")',
    y = "Dynamic Valence Rating"
  ) +
  scale_x_continuous(
      breaks = seq(0, 10*2*30, 30), 
      expand = c(0, 0),
      labels = s_to_ts
  ) +
  theme_bw(base_size = 20) +
  theme(panel.grid.minor = element_blank())
```

::: {.footer}
Each blue line is one participant's time series
:::

## Introducing the Chromodoris plot

```{r}
#| message: false
#| echo: false
#| warning: false
#| cache: true

  require("Hmisc")
  df2 |> 
    ggplot2::ggplot(
      ggplot2::aes(x = Second, y = Rating)
    ) +
    ggplot2::stat_summary(
      geom = "ribbon",
      fun.data = ggplot2::median_hilow,
      fun.args = list(conf.int = .9),
      fill = "#440154"
    ) +
    ggplot2::stat_summary(
      geom = "ribbon",
      fun.data = ggplot2::median_hilow,
      fun.args = list(conf.int = .7),
      fill = "#21908c"
    ) +
    ggplot2::stat_summary(
      geom = "ribbon",
      fun.data = ggplot2::median_hilow,
      fun.args = list(conf.int = .5),
      fill = "#fde725"
    ) +
    ggplot2::geom_hline(
      yintercept = 0, 
      color = "grey", 
      linewidth = 3/4
    ) +
    ggplot2::stat_summary(
      geom = "line", 
      fun = mean, 
      na.rm = TRUE, 
      linewidth = 1.5
    ) +
    ggplot2::scale_x_continuous(
      breaks = seq(0, 10*2*30, 30), 
      expand = c(0, 0),
      labels = s_to_ts
    ) +
    ggplot2::scale_y_continuous(
      expand = c(0, 0)
    ) +
    ggplot2::coord_cartesian(
      ylim = c(-4, 4)
    ) +
    ggplot2::labs(
      y = "Dynamic Valence Rating", 
      x = 'Timestamp within Clip ("The Green Mile")'
    ) +
    theme_bw(base_size = 20) +
    theme(panel.grid.minor = element_blank())

```

::: {.footer}
Black = Mean, Yellow = 50%, Green = 70%, Purple = 90%
:::

## Database Uses

- **Emotion elicitation** video set with normative data 

- Affective **content analysis** with average ratings

- Subjectivity analysis to predict **rating distributions**

- Subjectivity analysis to explain **degree of subjectivity**

- **Personalized modeling** of affective reactions

## Future Directions

1. Add more movie **clips** and **participants**

1. Add more dynamic and holistic rating **dimensions**

1. Add data from **sensors** (e.g., physiological and eye tracking)

1. Collect information about participants' **personality**

1. Collect similar data in **clinical/medical** populations

## Acknowledgements

::: {.nonincremental}

- **Co-authors**
    + Jeffrey Girard (University of Kansas)
    + Yanmei Tie (Brigham & Women's Hospital, HMS)
    + Einat Liebenthal (McLean Hospital, HMS)

- **Funding**
    + Alexandra Golby (Brigham & Women's Hospital, HMS)

- **Assistance**
    + Colin Gavin, Laura Rigolo, Abby Recko, Ben Phan
    
:::
    
## Questions? {.tc}

![](movie.svg)

<https://dynamos.mgb.org>
